# Kafka 介绍与实践

### 1.1 实验内容

前面一个课程讲解了 Kafka 的一些入门知识，本节课将介绍如何使用 Java 语言进行 Kafka 生产者和消费者代码的编写，毕竟大家使用 Kafka 集群是想发送消息到 Kafka ，然后从 Kafka 取出消息。学习完本课程，你将对 kafka 有深入的了解，很快上手。

### 1.2 课程来源

参考资料：[http://blog.sina.com.cn/s/blog_67196ddc0102w80o.html](http://blog.sina.com.cn/s/blog_67196ddc0102w80o.html)

### 1.3. 实验知识点

- 生产者
- 消费者
- java 代码编写

### 1.4 实验环境

- hadoop 2.6.1
- kafka_2.10-0.8.1.1
- Xfce 终端

### 1.5 适合人群

本课程属于中等难度级别，适合对大数据开发有兴趣，需要进行大量日志传输，并且有 Kafka 基础的人群。

## 二、实验步骤

### 2.1　准备工作

我们已经在实验楼环境里下载并配置启动 hadoop-2.6.1 所需的文件，免除您配置文件的麻烦，您可以在 `/opt` 找到，只需格式化并启动 hadoop 进程即可。

双击打开桌面上的 Xfce 终端，用 `sudo` 命令切换到 hadoop 用户，hadoop 用户密码为 hadoop，用 `cd` 命令进入 `/opt`目录。

```
$ su hadoop
$ cd /opt/

```

![此处输入图片的描述](https://dn-anything-about-doc.qbox.me/document-uid214292labid2657timestamp1491894012889.png/wm)

在 `/opt` 目录下格式化 hadoop。

```
$ hadoop-2.6.1/bin/hdfs namenode -format

```

![此处输入图片的描述](https://dn-anything-about-doc.qbox.me/document-uid214292labid2657timestamp1491894114007.png/wm)

在 `/opt` 目录下启动 hadoop 进程。

```
$ hadoop-2.6.1/sbin/start-all.sh

```

![此处输入图片的描述](https://dn-anything-about-doc.qbox.me/document-uid214292labid2657timestamp1491894286864.png/wm)

用 `jps` 查看 hadoop 进程是否启动。

![此处输入图片的描述](https://dn-anything-about-doc.qbox.me/document-uid214292labid2657timestamp1491894495396.png/wm)

在 /opt/ 目录下，用 `wget` 命令下载 `slf4j-1.7.22.zip` 并解压。

```
$ sudo wget http://labfile.oss.aliyuncs.com/courses/785/slf4j-1.7.22.zip
$ sudo  unzip slf4j-1.7.22.zip

```

![此处输入图片的描述](https://dn-anything-about-doc.qbox.me/document-uid214292labid2666timestamp1489654711102.png/wm)

![此处输入图片的描述](https://dn-anything-about-doc.qbox.me/document-uid214292labid2666timestamp1489654722816.png/wm)

复制 `slf4j-nop-1.7.22.jar` 到 Kafka 解压包的 `lib` 目录下。

```
$ sudo cp slf4j-1.7.22/slf4j-nop-1.7.22.jar kafka_2.10-0.8.1.1/libs

```

![此处输入图片的描述](https://dn-anything-about-doc.qbox.me/document-uid214292labid2666timestamp1489654938606.png/wm)

双击打开 eclipse -> file -> New -> Java Project

![此处输入图片的描述](https://dn-anything-about-doc.qbox.me/document-uid214292labid2666timestamp1489652263621.png/wm)

输入 Project name -> 选择 javaSe-1.7-> Finish

![此处输入图片的描述](https://dn-anything-about-doc.qbox.me/document-uid214292labid2666timestamp1489652474962.png/wm)

右键 src -> New -> Package

![此处输入图片的描述](https://dn-anything-about-doc.qbox.me/document-uid214292labid2666timestamp1489652636477.png/wm)

输入包名 -> Finish

![此处输入图片的描述](https://dn-anything-about-doc.qbox.me/document-uid214292labid2666timestamp1489652833817.png/wm)

添加 kafka jar

![此处输入图片的描述](https://dn-anything-about-doc.qbox.me/document-uid214292labid2666timestamp1489653007972.png/wm)

点击 Libraries->Add External JARs...-> 选中已经下载的 kafka libs 目录下的 jar-> 确定

![此处输入图片的描述](https://dn-anything-about-doc.qbox.me/document-uid214292labid2666timestamp1489655157340.png/wm)

点击 OK

![此处输入图片的描述](https://dn-anything-about-doc.qbox.me/document-uid214292labid2666timestamp1489655201163.png/wm)

### 2.2 编写 Produce

右键 sys.kafka -> New -> Class

![此处输入图片的描述](https://dn-anything-about-doc.qbox.me/document-uid214292labid2666timestamp1489655638125.png/wm)

输入类名 -> 确认

![此处输入图片的描述](https://dn-anything-about-doc.qbox.me/document-uid214292labid2666timestamp1489655725004.png/wm)

`ProducerDemo.java`如下。

```
package syl.kafka;
import java.util.Properties;
import kafka.javaapi.producer.Producer;
import kafka.producer.KeyedMessage;
import kafka.producer.ProducerConfig;

public class ProducerDemo {
    public static void main(String[] args) throws Exception {
        Properties props = new Properties();
        //zk
        props.put("zk.connect", "localhost:2181");
        //kafka broker
        props.put("metadata.broker.list","localhost:9092");

        //serialize
        props.put("serializer.class", "kafka.serializer.StringEncoder");
        ProducerConfig config = new ProducerConfig(props);
        Producer<String, String> producer = new Producer<String, String>(config);

        // read socket
        for (int i = 1; i <= 100000; i++) {
            //Thread.sleep(50);
            producer.send(new KeyedMessage<String, String>("test",
                    "message: " + i ));
        }

    }
}

```

### 2.3 编写 Consumer

右键点击 syl.kafka -> New -> Class

![此处输入图片的描述](https://dn-anything-about-doc.qbox.me/document-uid214292labid2666timestamp1489655638125.png/wm)

输入类名 -> 确认

![此处输入图片的描述](https://dn-anything-about-doc.qbox.me/document-uid214292labid2666timestamp1489657971307.png/wm)

`ConsumerDemo.java`如下。

```
package syl.kafka;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.Properties;
import kafka.consumer.Consumer;
import kafka.consumer.ConsumerConfig;
import kafka.consumer.ConsumerIterator;
import kafka.consumer.KafkaStream;
import kafka.javaapi.consumer.ConsumerConnector;
import kafka.message.MessageAndMetadata;

public class ConsumerDemo {
    private static final String topic = "test";
    private static final Integer threads = 1;
    public static void main(String[] args) {
        Properties props = new Properties();
        //zk
        props.put("zookeeper.connect", "localhost:2181");
        //group
        props.put("group.id", "group1");
        //offset
        props.put("auto.offset.reset", "smallest");
        ConsumerConfig config = new ConsumerConfig(props);
        ConsumerConnector consumer = Consumer.createJavaConsumerConnector(config);
        Map<String, Integer> topicCountMap = new HashMap<String, Integer>();
        topicCountMap.put(topic, 1);
        Map<String, List<KafkaStream<byte[], byte[]>>> consumerMap = consumer.createMessageStreams(topicCountMap);
        List<KafkaStream<byte[], byte[]>> streams = consumerMap.get(topic);

        for(final KafkaStream<byte[], byte[]> kafkaStream : streams){
            new Thread(new Runnable() {
                @Override
                public void run() {
                    for(MessageAndMetadata<byte[], byte[]> mm : kafkaStream){
                        String msg = new String(mm.message());
                        System.out.println(msg);
                    }
                }

            }).start();

        }
    }
}

```

启动 ZooKeeper 服务器。

```
$ /bin/zookeeper-server-start.sh config/zookeeper.properties &

```

![此处输入图片的描述](https://dn-anything-about-doc.qbox.me/document-uid214292labid2666timestamp1489721411456.png/wm)

接下来，启动 kafka 服务器。

```
$bin/kafka-server-start.sh config/server.properties &

```

![此处输入图片的描述](https://dn-anything-about-doc.qbox.me/document-uid214292labid2666timestamp1489721570739.png/wm)

上节课我们创建了 test 主题，并且 `ProducerDemo.java` 里指定了主题 test，所以可以直接使用。

![此处输入图片的描述](https://dn-anything-about-doc.qbox.me/document-uid214292labid2666timestamp1489721817899.png/wm)

若没有 test 主题，可以使用以下方式创建 (若存在主题，跳过此步)。

```
$ bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test

```

### 2.4 测试

用一个 comsumer 从 test 主题中读取信息

```
$ bin/kafka-console-consumer.sh --zookeeper localhost:2181 --from-beginning --topic test

```

![此处输入图片的描述](https://dn-anything-about-doc.qbox.me/document-uid214292labid2666timestamp1489722522209.png/wm)

运行写好的 `ProducerDemo.java`，同时观察消费者端的变化。

![此处输入图片的描述](https://dn-anything-about-doc.qbox.me/document-uid214292labid2666timestamp1489722902625.png/wm)

消费者 Xfce 终端不断消费消息。

![此处输入图片的描述](https://dn-anything-about-doc.qbox.me/document-uid214292labid2666timestamp1489723053470.png/wm)

停掉`ProducerDemo.java`，先运行`ConsumerDemo.java`。

![此处输入图片的描述](https://dn-anything-about-doc.qbox.me/document-uid214292labid2666timestamp1489723434744.png/wm)

等待接收信息。

![此处输入图片的描述](https://dn-anything-about-doc.qbox.me/document-uid214292labid2666timestamp1489723880395.png/wm)

查看 Eclipse 的 ConsumerDemo 的 Console 及消费者 Xfce 终端

再次运行 `ProducerDemo.java`。

![此处输入图片的描述](https://dn-anything-about-doc.qbox.me/document-uid214292labid2666timestamp1489723951086.png/wm)

观察结果。

![此处输入图片的描述](https://dn-anything-about-doc.qbox.me/document-uid214292labid2666timestamp1489726530551.png/wm)

## 三、实验总结

本节课程介绍了如何使用 java 编写生产者消费者并实践操作，对深入学习 kafka 有很大帮助。

## 四、参考文献

- [http://kafka.apache.org/documentation.html。](http://kafka.apache.org/documentation.html%E3%80%82)