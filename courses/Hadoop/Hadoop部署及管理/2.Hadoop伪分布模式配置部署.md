## 一、实验环境说明

* **注意：本实验需要按照上一节单机模式部署后继续进行操作**

### 1. 环境登录

无需密码自动登录，系统用户名 shiyanlou

### 2. 环境介绍

本实验环境采用带桌面的 Ubuntu Linux 环境，实验中会用到桌面上的程序：

- XfceTerminal：Linux 命令行终端，打开后会进入 Bash 环境，可以使用 Linux 命令
- Firefox：浏览器，可以用在需要前端界面的课程里，只需要打开环境里写的 HTML/JS 页面即可
- GVim：非常好用的编辑器，最简单的用法可以参考课程 Vim 编辑器

### 3. 环境使用

使用Vim编辑器输入实验所需的代码，然后使用Xfce终端命令行环境进行编译运行，查看运行结果，运行后可以截图并分享自己的实验报告，实验报告中的数据可以真实有效证明您已经完成了实验。

实验报告页面可以在“我的主页”中查看，其中含有每次实验的截图及笔记，以及每次实验的有效学习时间（指的是在实验桌面内操作的时间，如果没有操作，系统会记录为发呆时间）。这些都是您学习的真实性证明。

### 4. 参考文档

本实验参考下列文档内容制作：

- http://www.cnblogs.com/kinglau/p/3796164.html
- http://www.linuxidc.com/Linux/2012-01/50880p2.html

## 二、Hadoop伪分布式模式配置

###注意：本实验需要按照上一节单机模式部署后继续进行操作，因此您必须先完成上一节实验。

### 1. 相关配置文件修改

#### 1).修改`core-site.xml`:
```
$ sudo gvim /usr/local/hadoop/etc/hadoop/core-site.xml
```

```
&lt;?xml version=&#34;1.0&#34;?&gt;
&lt;?xml-stylesheet type=&#34;text/xsl&#34; href=&#34;configuration.xsl&#34;?&gt;

&lt;!-- Put site-specific property overrides in this file. --&gt;

&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;fs.default.name&lt;/name&gt;
        &lt;value&gt;hdfs://localhost:9000&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
        &lt;value&gt;/home/hadoop/tmp&lt;/value&gt;
   &lt;/property&gt;
&lt;/configuration&gt;
```

常用配置项说明：

- `fs.default.name`这是一个描述集群中NameNode结点的URI(包括协议、主机名称、端口号)，集群里面的每一台机器都需要知道NameNode的地址。DataNode结点会先在NameNode上注册，这样它们的数据才可以被使用。独立的客户端程序通过这个URI跟DataNode交互，以取得文件的块列表。
- `hadoop.tmp.dir` 是hadoop文件系统依赖的基础配置，很多路径都依赖它。如果hdfs-site.xml中不配置namenode和datanode的存放位置，默认就放在`/tmp/hadoop-${user.name}`这个路径中

更多说明请参考[core-default.xml](http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/core-default.xml)，包含配置文件所有配置项的说明和默认值。

#### 2).修改`hdfs-site.xml`:
```
$ sudo gvim /usr/local/hadoop/etc/hadoop/hdfs-site.xml
```

```
&lt;?xml version=&#34;1.0&#34;?&gt;
&lt;?xml-stylesheet type=&#34;text/xsl&#34; href=&#34;configuration.xsl&#34;?&gt;

&lt;!-- Put site-specific property overrides in this file. --&gt;

&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.replication&lt;/name&gt;
        &lt;value&gt;1&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
```
常用配置项说明：

- `dfs.replication`它决定着系统里面的文件块的数据备份个数。对于一个实际的应用，它应该被设为3（这个数字并没有上限，但更多的备份可能并没有作用，而且会占用更多的空间）。少于三个的备份，可能会影响到数据的可靠性(系统故障时，也许会造成数据丢失)
- `dfs.data.dir`这是DataNode结点被指定要存储数据的本地文件系统路径。DataNode结点上的这个路径没有必要完全相同，因为每台机器的环境很可能是不一样的。但如果每台机器上的这个路径都是统一配置的话，会使工作变得简单一些。默认的情况下，它的值为`file://${hadoop.tmp.dir}/dfs/data`这个路径只能用于测试的目的，因为它很可能会丢失掉一些数据。所以这个值最好还是被覆盖。
- `dfs.name.dir`这是NameNode结点存储hadoop文件系统信息的本地系统路径。这个值只对NameNode有效，DataNode并不需要使用到它。上面对于/temp类型的警告，同样也适用于这里。在实际应用中，它最好被覆盖掉。

更多说明请参考[hdfs-default.xml](http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml)，包含配置文件所有配置项的说明和默认值。

#### 3).修改`mapred-site.xml`:
```
$ sudo cp /usr/local/hadoop/etc/hadoop/mapred-site.xml.template /usr/local/hadoop/etc/hadoop/mapred-site.xml
$ sudo gvim /usr/local/hadoop/etc/hadoop/mapred-site.xml
```

```
&lt;?xml version=&#34;1.0&#34;?&gt;
&lt;?xml-stylesheet type=&#34;text/xsl&#34; href=&#34;configuration.xsl&#34;?&gt;

&lt;!-- Put site-specific property overrides in this file. --&gt;

&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;
        &lt;value&gt;yarn&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
```

常用配置项说明：

- `mapred.job.tracker`JobTracker的主机（或者IP）和端口。

更多说明请参考[mapred-default.xml](http://hadoop.apache.org/docs/stable/hadoop-mapreduce-client/hadoop-mapreduce-client-core/mapred-default.xml)，包含配置文件所有配置项的说明和默认值

#### 4).修改`yarn-site.xml`:
```
&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&lt;/name&gt;
        &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
```

常用配置项说明：

- `yarn.nodemanager.aux-services`通过该配置，用户可以自定义一些服务

更多说明请参考[yarn-default.xml](http://hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-yarn-common/yarn-default.xml)，包含配置文件所有配置项的说明和默认值

#### 5). 修改 `hadoop-env.sh`:

```
$ sudo vim /usr/local/hadoop/etc/hadoop/hadoop-env.sh
```

修改 JAVA_HOME 如下：

![图片描述信息](https://dn-anything-about-doc.qbox.me/userid46108labid162time1432704021216?watermark/1/image/aHR0cDovL3N5bC1zdGF0aWMucWluaXVkbi5jb20vaW1nL3dhdGVybWFyay5wbmc=/dissolve/60/gravity/SouthEast/dx/0/dy/10)


这样简单的伪分布式模式就配置好了。

## 三、格式化HDFS文件系统
在使用hadoop前，必须格式化一个全新的HDFS安装，通过创建存储目录和NameNode持久化数据结构的初始版本，格式化过程创建了一个空的文件系统。由于NameNode管理文件系统的元数据，而DataNode可以动态的加入或离开集群，因此这个格式化过程并不涉及DataNode。同理，用户也无需关注文件系统的规模。集群中DataNode的数量决定着文件系统的规模。DataNode可以在文件系统格式化之后的很长一段时间内按需增加。

### 1.先切换到hadoop账户，按照提示输入账户密码
```
$ su hadoop
```

### 2.格式化HDFS文件系统
```
$ hadoop namenode -format
```

会输出如下信息，则表格式化HDFS成功：
```
DEPRECATED: Use of this script to execute hdfs command is deprecated.
Instead use the hdfs command for it.

INFO namenode.NameNode: STARTUP_MSG:
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = [你的主机名]/127.0.0.1
STARTUP_MSG:   args = [-format]
STARTUP_MSG:   version = 2.4.1
...
...
INFO util.ExitUtil: Exiting with status 0
INFO namenode.NameNode: SHUTDOWN_MSG:
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at [你的主机名]/127.0.0.1
************************************************************/
```

## 四、Hadoop集群启动
### 1.启动hdfs守护进程，分别启动NameNode和DataNode
```
$ hadoop-daemon.sh start namenode
$ hadoop-daemon.sh start datanode
```

或者一次启动
```
$ start-dfs.sh
```

输出如下（可以看出分别启动了namenode, datanode, secondarynamenode，因为我们没有配置secondarynamenode，所以地址为0.0.0.0）：
```
Starting namenodes on []
hadoop@localhost&#39;s password:
localhost: starting namenode, logging to /usr/local/hadoop/logs/hadoop-hadoop-namenode-G470.out
hadoop@localhost&#39;s password:
localhost: starting datanode, logging to /usr/local/hadoop/logs/hadoop-hadoop-datanode-G470.out
localhost: OpenJDK 64-Bit Server VM warning: You have loaded library /usr/local/hadoop/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
localhost: It&#39;s highly recommended that you fix the library with &#39;execstack -c &lt;libfile&gt;&#39;, or link it with &#39;-z noexecstack&#39;.
Starting secondary namenodes [0.0.0.0]
hadoop@0.0.0.0&#39;s password:
0.0.0.0: starting secondarynamenode, logging to /usr/local/hadoop/logs/hadoop-hadoop-secondarynamenode-G470.out

```

### 2.启动yarn,使用如下命令启ResourceManager和NodeManager:

```
$ yarn-daemon.sh start resourcemanager
$ yarn-daemon.sh start nodemanager
```

或者一次启动：

```
$ start-yarn.sh
```

### 3.检查是否运行成功
打开浏览器

- 输入：`http://localhost:8088`进入ResourceManager管理页面
- 输入：`http://localhost:50070`进入HDFS页面

####可能出现的问题及调试方法：

启动伪分布后，如果活跃节点显示为零，说明伪分布没有真正的启动。原因是有的时候数据结构出现问题会造成无法启动datanode。如果使用`hadoop namenode -format `重新格式化仍然无法正常启动，原因是`/tmp`中的文件没有清除，则需要先清除`/tmp/hadoop/*`再执行格式化，即可解决hadoop datanode无法启动的问题。具体步骤如下所示：

```
# 删除hadoop:/tmp
$ hadoop fs -rmr /tmp
# 停止hadoop
$ stop-all.sh
# 删除/tmp/hadoop*
$ rm -rf /tmp/hadoop*
# 格式化
$ hadoop namenode -format
# 启动hadoop
$ start-all.sh
```

## 六、测试验证

测试验证还是使用上一节的 WordCount。

不同的是，这次是伪分布模式，使用到了 hdfs，因此我们需要把文件拷贝到 hdfs 上去。

首先创建相关文件夹（要一步一步的创建）：

```
$ hadoop dfs -mkdir /user
$ hadoop dfs -mkdir /user/hadoop
$ hadoop dfs -mkdir /user/hadoop/input
```

### 1.创建输入的数据，采用/etc/protocols文件作为测试

先将文件拷贝到 hdfs 上：

```
$ hadoop dfs -put /etc/protocols /user/hadoop/input
```

![图片描述信息](https://dn-anything-about-doc.qbox.me/userid46108labid162time1432704272851?watermark/1/image/aHR0cDovL3N5bC1zdGF0aWMucWluaXVkbi5jb20vaW1nL3dhdGVybWFyay5wbmc=/dissolve/60/gravity/SouthEast/dx/0/dy/10)

### 2.执行Hadoop WordCount应用（词频统计）
```
# 如果存在上一次测试生成的output，由于hadoop的安全机制，直接运行可能会报错，所以请手动删除上一次生成的output文件夹
$ bin/hadoop jar share/hadoop/mapreduce/sources/hadoop-mapreduce-examples-2.6.0-sources.jar org.apache.hadoop.examples.WordCount input output
```

执行过程截图（部分）：

![图片描述信息](https://dn-anything-about-doc.qbox.me/userid46108labid162time1432704408420?watermark/1/image/aHR0cDovL3N5bC1zdGF0aWMucWluaXVkbi5jb20vaW1nL3dhdGVybWFyay5wbmc=/dissolve/60/gravity/SouthEast/dx/0/dy/10)

### 3.查看生成的单词统计数据

```
$ hadoop dfs -cat /user/hadoop/output/*
```

![图片描述信息](https://dn-anything-about-doc.qbox.me/userid46108labid162time1432704326176?watermark/1/image/aHR0cDovL3N5bC1zdGF0aWMucWluaXVkbi5jb20vaW1nL3dhdGVybWFyay5wbmc=/dissolve/60/gravity/SouthEast/dx/0/dy/10)

## 七、关闭服务
输入命令
```
$ hadoop-daemon.sh stop namenode
$ hadoop-daemon.sh stop datanode
$ yarn-daemon.sh stop resourcemanager
$ yarn-daemon.sh stop nodemanager
```

或者
```
$ stop-dfs.sh
$ stop-yarn.sh
```

最后一步：点击屏幕上方的“实验截图”将上述命令执行后的截图保存并分享给朋友们吧，这是你学习Hadoop安装的证明。

##八、小结

本实验讲解如何在单机模式下继续部署Hadoop为伪分布模式。

##九、思考题

伪分布模式和单机模式配置上的区别主要是哪些？是否可以推论出如何部署真实的分布式Hadoop环境？

实验中有任何问题欢迎到[实验楼问答](http://www.shiyanlou.com/questions)提问。



