# 自编码器实现

## 一、课程介绍

### 1.1 内容简介 

目前许多有监督学习算法，如SVM，DNN或是boosting，决策树等，都在工业界分类或决策任务上取得了不错的成果。但是这些有监督学习需要大量带标签的数据，对数据进行上标签又是一个需耗费人力与时间的任务。有许多数据都是不带标签的，因此我们可利用无监督学习对其进行聚类或特征提取。利用无监督学习得到的特征结果也可应用到带标记数据较少的有监督学习任务中，提高其分类性能。

引用目前热门的深度学习领域大牛 LeCun, Bengio, Hiton在国外著名期刊Nature的话，我们就可得知无监督学习的应用在机器学习领域的重要性：

> "We expect unsupervised learning to become far more important in the longer term. Human and animal learning is largely unsupervised: we discover the structure of the world by observing it, not by being told the name of every object" - LeCun, Bengio, Hinton, Nature 2015

通过上节课对`无监督学习`及`自编码器`的介绍，本节课将实现上节课所提到的三层全连接神经网络，实现`为数据可视化而降维`的简易自编码器。

### 1.2 编码效果

我们的自编码器在迭代训练了500次后，将数据降维由`784`降至`32`后的编码结果，在此编码基础上复原图片的效果在 _实验结果_ 展示。

![code result](https://dn-anything-about-doc.qbox.me/document-uid291340labid2288timestamp1478767354016.png/wm)

### 1.3 知识点

- 归一化
- 批量梯度下降 Batch gradient descent
- 随机梯度下降 Stochastic gradient descent
- 最小批梯度下降 Mini-batch gradient descent

## 二、实验原理

### 数据预处理

在实验过程中，我们用一个列向量表示一个图片样本，如数字图片维度为`$$28*28$$`时，我们用`$$784*1$$`的列向量表示其数据，这个过程称为`向量化`数据。由于输入灰度图片像素值范围在`0~255`，为加快网络的训练收敛，且原始图像数据由于是0-255的unit数据为便于`python`里的浮点型运算，我们将图像数据`归一化`至0-1区间。

这里我们采用的`归一化`方法为`最小-最大标准化（Min-Max Nomalization）`，转换函数如下：

`$$
x^* = \frac{x-min}{max-min}
$$`

由于这里图像数据的最大值为255，最小值为0，故在实验过程中，我们归一化时直接将原始数据除以255即可。

### 自编码器训练过程

回顾在[自联想器的Python实现](http://www.shiyanlou/courses/679)中我们介绍神经网络时曾经说到，网络的训练（学习）过程就是权值矩阵的调整过程。 而在人工神经网络中，学习过程也分成很多种。众所周知，机器学习的三大类可分为：

1. 无监督学习
2. 有监督学习
3. 强化学习

上节课程中，我们介绍了前面两种，其实还有一种属于这两种学习的折中，称为`半监督学习`，同时利用无标记和有标记的数据进行训练。

若按照学习过程(权值的更新方法)中，一次使用多少个样本对权值进行更新划分，可划分成：

1. 离线学习 / 批梯度下降
2. 在线学习 / 随机梯度下降 
3. 最小批梯度下降

`批梯度下降`是在所有的数据样本训练完毕之后，累加所有样本对权值的更新值，对权值进行一次更新，在训练过程中当有新的样本出现时，我们的权值也没有进行及时的更新，故也称为`离线学习`。 `随机梯度下降`是每次只用一个样本对权值进行更新，所以当新的样本出现时，我们也能及时更新权值，故也称为`在线学习`。

`批梯度下降`算法需要所有的样本进行一次权值更新，若是数据集中有很多样本时，每次更新说花费的时间就很多。而`随机梯度下降`虽比`批梯度下降算法`更行权值速度快，但是由于更新得过于频繁，且单个样本所得到的`代价函数`比用所有样本得到的`代价函数`更具有随机性，可能无法找到逼近于我们想要的恒等函数`$$h_{w,b}(x)=x$$`的最优解。故我们采取了一种折中的学习过程，`mini-batch learning最小批训练`。即每次训练时，只用所有数据中的一部分数据对权值进行更新。

在我们的训练过程中，数据样本集大小为500，每次更新权值时使用100张图像对其进行更新。这里我们设置的总训练次数（即迭代次数）为500次，也可根据代价函数 `$$
C =\frac{1}{2}\sum_{i=1}^{n}(\hat{x}_i - x_i)^2
$$`，当根据代价函数计算所得的误差小于某个 任意小的`$$\epsilon, \epsilon>0$$`时停止训练。

## 三、实验操作

### 3.1 安装 scipy, numpy 及 matplot

为了节省读取数据的时间，我们在本次实验中只用了500张minist数字手写体数据库中的数字， `0-9`十个数字每个数字都用50张数字图片与之对应， 并且为节约每个图片读取的时间，我们将这500张图片已经保存至一个`.mat`文件中，可直接通过`scipy`模块中的`scio.loadmat`函数读取， 并且由于此次训练仍设计到矩阵运算及结果展示，因此我们需先下载安装 scipy, numpy 及 matplot 这三个 Python 的第三方库。

```bash
$ sudo pip install scipy
$ sudo pip install numpy
$ sudo pip install matplotlib
```

为使用这些第三方包，还需安装python-tk

```bash
sudo apt-get install python-tk
```

### 3.2 程序实现

创建目录 autoencoder, 进入目录后获得训练数据 `trainData.mat` 并创建 AE.py 文件

```bash
mkdir autoencoder && cd autoencoder
wget http://labfile.oss.aliyuncs.com/courses/696/trainData.mat
touch AE.py
```

编辑 AE.py, 导入实验相关的模块

```python
# -*- coding: utf-8 -*-
import scipy.io as scio
import numpy as np
import matplotlib.pyplot as plt
import random
```

在main函数中，先导入预先准备好的训练数据，并将其归一化：

```python
def main():
    trainData = scio.loadmat('trainData.mat')

    unlabeled_data = trainData['trainData']
    unlabeled_data = unlabeled_data[:,:] / 255.
```

设置自编码器三层神经网络训练所需参数：

```python
    alpha = 5 # 学习步长
    max_epoch = 500 # 训练得最大迭代次数
    mini_batch = 100 # 在线学习批训练一次训练得次数
    imgSize = 784 # 每张图片的大小，共784个像素

    # 定义神经网络结构
    # 第一列为外部节点（神经元）
    # 第二列为内部节点，最后一层为网络输出
    layer_struc = [[imgSize, 1],
                   [0, 32],
                   [0, imgSize]]
    layer_num = 3

    # 初始化权值矩阵
    w = []
    for l in range(layer_num-1):
        w.append(np.random.randn(layer_struc[l+1][1],sum(layer_struc[l])))

    dataset_size = 500  # 训练数据集大小
    
    # 定义神经网络的外部输入
    # 虽然只有第一层外部输入
    # 但是为了训练时代码的统一，也设置了最后两层空的外部输入
    X = []
    X.append(np.array(unlabeled_data[:,:]))
    X.append(np.zeros((0,dataset_size)))
    X.append(np.zeros((0,dataset_size)))
    
    # 初始化误差反向传播时所需的δ
    delta = []
    for l in range(layer_num):
        delta.append([])
    
    # 定义结果展示的参数 
    # 每隔100个epoch展示一次自编码结果
    # 加上第一行的原始图片展示
    nRow = max_epoch / 100 + 1
    nColumn = 10   # 每一行展示0-9十个数字
    eachDigitNum = 50  # 每个数字都有50张训练图片
```

往结果展示面板第一行添加10张原始图片

```python
    for iImg in range(nColumn):
        ax = plt.subplot(nRow, nColumn, iImg+1)
        plt.imshow(unlabeled_data[:,eachDigitNum * iImg + 1].reshape((28,28)).T, cmap= plt.cm.gray)
    
        ax.get_xaxis().set_visible(False)
        ax.get_yaxis().set_visible(False)
```

所有参数设置等前期工作做完，即可开始我们的自编码器的训练：

```python
    count = 0 # 迭代次数计步器
    print('Autoencoder training start..')
    for iter in range(max_epoch):

        # 定义shuffle时的下标
        # 可理解为每次训练时都将训练数据重新打乱一遍
        ind = list(range(dataset_size))
        random.shuffle(ind)
        
        a = [] # 网络内部神经元 
        z = [] # 网络节点的加权叠加结果
        z.append([])
        
        # 对神经网络开始批训练
        for i in range(int(np.ceil(dataset_size / mini_batch))):
            a.append(np.zeros((layer_struc[0][1], mini_batch)))
            x = []
            for l in range(layer_num):
                x.append( X[l][:,ind[i*mini_batch : min((i+1)*mini_batch, dataset_size)]])

            # 定义目标输出
            y = unlabeled_data[:,ind[i*mini_batch:min((i+1)*mini_batch,dataset_size)]]
            
            # 调用前向计算函数计算网络每一层节点的值
            for l in range(layer_num-1):
                a.append([])
                z.append([])
                a[l+1],z[l+1] = feedforward(w[l],a[l],x[l])
            
            # 根据最小二乘代价函数计算最后一层的δ
            # 即自编码器的实际输出与目标值的欧式距离
            delta[layer_num-1] = np.array(a[layer_num-1] - y) * np.array(a[layer_num-1])
            delta[layer_num-1] = delta[layer_num-1] * np.array(1-a[layer_num-1])
            
            # 误差反向传播过程
            # 调用backprop函数逐层反向计算 δ 值
            for l in range(layer_num-2, 0, -1):
                delta[l] = backprop(w[l],z[l],delta[l+1])

            for l in range(layer_num-1):
                dw = np.dot(delta[l+1], np.concatenate((a[l],x[l]),axis=0).T) / mini_batch
                w[l] = w[l] - alpha * dw
       
        count = count + 1  
         
        
       
        # 展示自编码器编码结果 
        if np.mod(iter+1,100) == 0 :
            b = []
            b.append(np.zeros((layer_struc[0][1],dataset_size)))

            for l in range(layer_num-1):
                tempA, tempZ = feedforward(w[l], b[l], X[l])                
                b.append(tempA)

            for iImg in range(nColumn):
                ax = plt.subplot(nRow,nColumn, iImg + nColumn * (iter+1)/100 + 1)
                dis_result = b[layer_num-1][:,eachDigitNum * iImg + 1].reshape(28,28).T
                plt.imshow(dis_result,cmap= plt.cm.gray) 
                ax.get_xaxis().set_visible(False)
                ax.get_yaxis().set_visible(False)
                            
            print('Learning epoch:', count, '/', max_epoch)
    
    plt.show()
```

## 四、实验结果

输入`python AE.py` 运行自编码器， 查看其中训练数据中，其中十张数字图片原始图片及其自编码复原图片结果：

原始图片：

![original](https://dn-anything-about-doc.qbox.me/document-uid291340labid2288timestamp1478767185263.png/wm)

第100次迭代结果：

![iter100](https://dn-anything-about-doc.qbox.me/document-uid291340labid2288timestamp1478767213429.png/wm)

第200次迭代结果：

![iter200](https://dn-anything-about-doc.qbox.me/document-uid291340labid2288timestamp1478767233751.png/wm)

第300次迭代结果：

![iter300](https://dn-anything-about-doc.qbox.me/document-uid291340labid2288timestamp1478767253289.png/wm)

第400次迭代结果：

![iter400](https://dn-anything-about-doc.qbox.me/document-uid291340labid2288timestamp1478767279527.png/wm)

第500次迭代结果：

![iter500](https://dn-anything-about-doc.qbox.me/document-uid291340labid2288timestamp1478767298559.png/wm)

可通过以下命令获取此次课程的源码：

```bash
wget http://labfile.oss.aliyuncs.com/courses/696/AE.py
```

## 五、 总结

本节课程中我们实现了基于无监督学习的自编码器，网络的参数设置会影响自编码器的性能，包括训练步长，迭代次数，批训练中一次训练多少次图片等，如在本次实验结果中，我们便可看到随迭代次数的增加自编码的结果愈好，但是当训练到一定次数之后，训练结果就会不会随着迭代次数增多而出现太大的变动。同学们可在后续操作中改变这些参数，看训练结果有何不同。目前对这些参数的设置大多数都靠经验，或者启发式的设置。因此在设置好网络后，很多时候都需要花大量的时间调参以获得更好的结果。本节课程中的自编码器属于最简易的自编码器，在训练时对隐藏层加上稀疏限制或是利用卷积层搭建自编码器，可达到对原始数据进行降维后稀疏表达，或是降噪的效果。有兴趣的同学可在参考阅读中了解，利用基于theano的深度学习库keras实现。

## 六、参考阅读

- [利用keras实现花式自动编码器](http://keras-cn.readthedocs.io/en/latest/blog/autoencoder/)
- [ufldl 自编码算法与稀疏性](http://deeplearning.stanford.edu/wiki/index.php/%E8%87%AA%E7%BC%96%E7%A0%81%E7%AE%97%E6%B3%95%E4%B8%8E%E7%A8%80%E7%96%8F%E6%80%A7)