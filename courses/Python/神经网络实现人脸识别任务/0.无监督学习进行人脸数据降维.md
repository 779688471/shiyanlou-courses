# 自编码器进行人脸数据降维

## 一、课程介绍

### 1.1 内容简介

虽然目前深度学习取得了非常不错的成果，但是由于网络结构复杂，训练非常耗时。而且目前要进行深度学习的分类训练需要大量的带标记数据，对这些数据进行标记是非常耗时耗人力的。因此我们可用`无监督学习`利用无标记数据提取特征，并且利用无标记数据基于无监督学习对数据进行降维后，结合有标记数据基于`有监督学习`进行分类训练，实现人脸识别，图像分类等任务。

本次课程我们将利用在 [基于无监督学习的自编码器实现](https://www.shiyanlou.com/courses/696) 课程中介绍过的自编码器，实现对[耶鲁大学人脸数据库B+](http://vision.ucsd.edu/content/extended-yale-face-database-b-b)中的人脸图片数据进行降维，再利用降维后的人脸数据进行`有监督神经网络学习`进行分类器训练，最终达到人脸识别的目的。

### 1.2 知识点

- 人脸识别
- 人脸数据库
- 数据降维

### 1.3 课程流程

本次人脸识别应用的实现流程为：

1. 人脸数据准备
2. 人脸识别自编码器实现
3. 人脸识别分类器实现

### 1.4 人脸自编码器效果截图

本次课程实现的是对`Yale B+数据库`中的4张人脸进行识别的任务，以下每一列分别代表其中的一个人

原始图像：

![original faces](https://dn-anything-about-doc.qbox.me/document-uid291340labid2300timestamp1479451308403.png/wm)

第100次自编码器训练结果：

![iter 100](https://dn-anything-about-doc.qbox.me/document-uid291340labid2300timestamp1479451337873.png/wm)

第200次自编码器训练结果：

![iter 200](https://dn-anything-about-doc.qbox.me/document-uid291340labid2300timestamp1479451383444.png/wm)

第300次自编码器训练结果：

![iter 300](https://dn-anything-about-doc.qbox.me/document-uid291340labid2300timestamp1479451409401.png/wm)

## 二、实验原理

### 2.1 人脸识别任务及 yale B+ 数据库介绍

人脸识别维基百科定义：

> 广义的人脸识别实际包括构建人脸识别系统的一系列相关技术，包括人脸图像采集、人脸定位、人脸识别预处理、身份确认以及身份查找等；而狭义的人脸识别特指通过人脸进行身份确认或者身份查找的技术或系统。
人脸识别是一项热门的计算机技术研究领域，它属于生物特征识别技术，是对生物体（一般特指人）本身的生物特征来区分生物体个体。生物特征识别技术所研究的生物特征包括脸、指纹、手掌纹、虹膜、视网膜、声音（语音）、体形、个人习惯（例如敲击键盘的力度和频率、签字）等，相应的识别技术就有人脸识别、指纹识别、掌纹识别、虹膜识别、视网膜识别、语音识别（用语音识别可以进行身份识别，也可以进行语音内容的识别，只有前者属于生物特征识别技术）、体形识别、键盘敲击识别、签字识别等。


本次实验，我们所用的[耶鲁大学人脸数据库B+](http://vision.ucsd.edu/content/extended-yale-face-database-b-b)

![B+数据库](https://dn-anything-about-doc.qbox.me/document-uid291340labid2300timestamp1479455279939.png/wm)

可点击`Download`下方的链接进入下载页面：

![download_pad](https://dn-anything-about-doc.qbox.me/document-uid291340labid2300timestamp1479455996199.png/wm)

点击`Cropped_Images`下载裁剪过后的数据，裁剪好的图片数据中不包含其他背景，仅有人脸（不包括头发，耳朵等），本次课程中只用了下载好的数据`CroppedYale`中的其中四个人脸数据集`yaleB01`,`yaleB02`,`yaleB03`和`yaleB04`。数据库中每张人脸数据大小为`192 x 168`，对于每个人都有64张人脸图片，分别是在不同光照条件下拍摄得的。 为了节约计算时间，我们将原始数据的维度改成`48 x 42`，并且从每个文件夹中选出20张图片当做无监督学习时的数据集，14张作为有监督训练时的训练数据，10张为有监督训练的测试数据。

### 2.2 神经网络总结构

我们的神经网络由两部分组成，第一部分为`自编码器`训练完毕后的编码部分，第二部分为`有监督训练`单层网络，在[基于无监督学习的自编码器实现](https://www.shiyanlou.com/courses/696)中我们已经详细地介绍过自编码器的原理，这里我们将运用其作为对人脸进行`数据降维`,再结合有监督学习结合有标记数据进行分类训练。

自编码器结构：

![自编码器](https://dn-anything-about-doc.qbox.me/document-uid291340labid2300timestamp1479458755797.png/wm)

自编码器网络结构：

![自编码器_网络结构](https://dn-anything-about-doc.qbox.me/document-uid291340labid2300timestamp1479458805483.png/wm)

总体网络结构，对于每个不同的人，我们采用一个四维列向量对其表达，这些列向量即是对不同人（类别）的`数据标记`：

![神经网络总体结构](https://dn-anything-about-doc.qbox.me/document-uid291340labid2300timestamp1479458896226.png/wm)

## 三、实验操作

### 3.1 下载安装第三方python包

安装实验所需的第三方包 scipy, numpy, matplotlib，及下载所需的实验数据，及下载安装python-tk
```bash
sudo pip install scipy
sudo pip install numpy
sudo pip install matplotlib
sudo wget install python-tk
```

### 3.2 实验数据下载

由于处理数据是一个繁琐的过程，并不是本次课程主要核心内容，因此我们已将数据处理好并放置在`yaleB_face_dataset.mat`文件中，可通过以下命运获取此文件：

```python
wget http://labfile.oss.aliyuncs.com/courses/707/yaleB_face_dataset.mat
```


### 3.3 自编码器实现

在与`yaleB_face_database.mat`同个目录下创建`face_recognition.py`并编写，导入相关python包
```bash
vim face_recognition.py
```

```python
import scipy.io as scio
import numpy as np
import matplotlib.pyplot as plt
```

进行神经网络所必须的`前向传播计算 feedforward computing` 和 `误差反向传播 backpropagation` 实现。

前向传播计算：

``` python
def feedforward(w,a,x):
    # sigmoid 激活函数
    f = lambda s: 1 / (1 + np.exp(-s)) 
    
    w = np.array(w)
    temp = np.array(np.concatenate((a,x),axis=0))
    z_next = np.dot(w , temp)
    
    return f(z_next), z_next

```

误差反向传播计算：

```python
def backprop(w,z,delta_next):

    # sigmoid 激活函数
    f = lambda s: np.array(1 / (1 + np.exp(-s)))
    

    # sigmoid 激活函数的导数
    df = lambda s: f(s) * (1 - f(s))
    
    
    delta = df(z) * np.dot(w.T,delta_next)    

    return delta
```

导入准备好的人脸数据，并对其进行归一化：
``` python
DataSet = scio.loadmat('yaleB_face_dataset.mat')
unlabeledData = DataSet['unlabeled_data']

dataset_size = 80 # 我们所准备无标签的人脸图片数据数量
unlabeled_data = np.zeros(unlabeledData.shape)

# 利用z-score归一化方法归一数据
for i in range(dataset_size):
    tmp = unlabeledData[:,i] / 255.
    unlabeled_data[:,i] = (tmp - np.mean(tmp)) / np.std(tmp)    
```

设置自编码器无监督训练参数，及神经网络结构：

```python
alpha = 0.5 # 学习步长
max_epoch = 300 # 自编码器训练总次数
mini_batch = 10 # 最小批训练时，每次使用10个样本同时进行训练
height = 48  # 人脸数据图片的高度
width = 42 # 人脸数据图片的宽度
imgSize = height * width 
   
# 神经网络结构
hidden_node = 60 # 网络隐藏层节点数目
hidden_layer = 2 
layer_struc = [[imgSize, 1],
               [0, hidden_node],
               [0, imgSize]]
layer_num = 3 # 网络层次数目

# 初始化无监督网络的权值
w = []
for l in range(layer_num-1):
    w.append(np.random.randn(layer_struc[l+1][1],sum(layer_struc[l])))

# 定义神经网络的外部节点数目
X = []
X.append(np.array(unlabeled_data[:,:]))
X.append(np.zeros((0,dataset_size)))
X.append(np.zeros((0,dataset_size)))

# 初始化在网络训练过程中，进行误差反向传播所需的 δ
delta = []
for l in range(layer_num):
    delta.append([])
```

从预先准备好的人脸数据中显示其中每个人的一张图片,原始图片将和训练过程中自编码器的输出结果展示在同一面板中

```python
# 定义结果展示参数
nRow = max_epoch / 100 + 1 
nColumn = 4   
eachFaceNum = 20 # 对于每个人都有20张未标记图像数据

# 在第一行中展示原始图像
for iImg in range(nColumn):
    ax = plt.subplot(nRow, nColumn, iImg+1)
    plt.imshow(unlabeledData[:,eachDigitNum * iImg + 1].reshape((width,height)).T, cmap= plt.cm.gray)
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
```

万事俱备，现在我们开始人脸图像自编码器的训练过程：
```python
#无监督训练
count = 0 # 记录训练次数
print('Autoencoder training start..')
for iter in range(max_epoch):

    # 定义随机洗牌下标
    ind = list(range(dataset_size))
    random.shuffle(ind)
    
    a = []
    z = []
    z.append([])
    for i in range(int(np.ceil(dataset_size / mini_batch))):
        a.append(np.zeros((layer_struc[0][1], mini_batch)))
        x = []
        for l in range(layer_num):
            x.append( X[l][:,ind[i*mini_batch : min((i+1)*mini_batch, dataset_size)]])

        y = unlabeled_data[:,ind[i*mini_batch:min((i+1)*mini_batch,dataset_size)]]
        for l in range(layer_num-1):
            a.append([])
            z.append([])
            a[l+1],z[l+1] = feedforward(w[l],a[l],x[l])
        
        
        delta[layer_num-1] = np.array(a[layer_num-1] - y) * np.array(a[layer_num-1])
        delta[layer_num-1] = delta[layer_num-1] * np.array(1-a[layer_num-1])
        
        for l in range(layer_num-2, 0, -1):
            delta[l] = backprop(w[l],z[l],delta[l+1])

        for l in range(layer_num-1):
            dw = np.dot(delta[l+1], np.concatenate((a[l],x[l]),axis=0).T) / mini_batch
            w[l] = w[l] - alpha * dw
   
    count = count + 1  
     
    
   
    # 每训练100次展示一次自编码器目前对原始图像的输出结果
    if np.mod(iter+1,100) == 0 :
        b = []
        b.append(np.zeros((layer_struc[0][1],dataset_size)))

        for l in range(layer_num-1):
            tempA, tempZ = feedforward(w[l], b[l], X[l])                
            b.append(tempA)

        for iImg in range(nColumn):
            fig1
            ax = plt.subplot(nRow,nColumn, iImg + nColumn * (iter+1)/100 + 1)
            tmp = b[layer_num-1][:,eachDigitNum * iImg + 1]
            dis_result = ((tmp * np.std(tmp)) + np.mean(tmp)).reshape(width,height).T
            plt.imshow(dis_result,cmap= plt.cm.gray) 
            ax.get_xaxis().set_visible(False)
            ax.get_yaxis().set_visible(False)
                        
        print('Learning epoch:', count, '/', max_epoch)
```

## 四、 总结

这节课程我们介绍了一个人脸数据库，并且利用自编码器对其进行了数据降维，将维度从`2016`降至`56`，下节课程我们将实现利用将这个降维后的数据进行有监督训练的网络，最终实现人脸识别的任务。

我们也可通过以下代码，展示自编码器训练结束时，自编码器对数据的编码效果：

```python
fig2 = plt.figure(2)

# 获得编码结果
code_result, tempZ = feedforward(w[0], b[0], X[0])

# 展示原始数据图
for iImg in range(nColumn):
    ax = plt.subplot(2, nColumn, iImg+1)
    plt.imshow(unlabeled_data[:,eachDigitNum * iImg + 1].reshape((width,height)).T, cmap= plt.cm.gray)
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)

# 展示对应的编码结果
for iImg in range(nColumn):
    ax = plt.subplot(2,nColumn,iImg+nColumn+1)
    plt.imshow(code_result[:,eachDigitNum * iImg + 1].reshape((hidden_node,1)), cmap=plt.cm.gray)
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
```

编码效果图：

![编码结果](https://dn-anything-about-doc.qbox.me/document-uid291340labid2300timestamp1479462081866.png/wm)

## 五、参考阅读

- [60个人脸数据库介绍](https://www.kairos.com/blog/60-facial-recognition-databases)
- [UFLDL-栈式自编码器](http://ufldl.stanford.edu/wiki/index.php/Stacked_Autoencoders)
- [知乎-为什么稀疏自编码器很少见到多层的](https://www.zhihu.com/question/41490383)