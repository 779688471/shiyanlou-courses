# 利用有监督学习进行人脸识别

## 一、课程介绍

### 1.1 内容简介

虽然目前深度学习取得了非常不错的成果，但是由于网络结构复杂，训练非常耗时。而且目前要进行深度学习的分类训练需要大量的带标记数据，对这些数据进行标记是非常耗时耗人力的。因此我们可用`无监督学习`利用无标记数据提取特征，并且利用无标记数据基于无监督学习对数据进行降维后，结合有标记数据基于`有监督学习`进行分类训练，实现人脸识别，图像分类等任务。

本次课程我们将利用在 [基于无监督学习的自编码器实现](https://www.shiyanlou.com/courses/696) 课程中介绍过的自编码器，实现对[耶鲁大学人脸数据库B+](http://vision.ucsd.edu/content/extended-yale-face-database-b-b)中的人脸图片数据进行降维，再利用降维后的人脸数据进行`有监督神经网络学习`进行分类器训练，最终达到人脸识别的目的。

通过上节课程对我们应用的介绍，及在自编码器基础上实现了数据降维后，本节课程我们将降维后的数据编码作为有监督学习网络的输入，实现人脸识别分类器。

### 1.2 基于`有监督学习`的分类器训练结果展示

随着训练次数的增加，分类器预测正确率的变化：

![正确率](https://dn-anything-about-doc.qbox.me/document-uid291340labid2301timestamp1479459682174.png/wm)

随着训练次数的增加，分类器的实际输出与目标输出间误差的变化：

![误差](https://dn-anything-about-doc.qbox.me/document-uid291340labid2301timestamp1479459754649.png/wm)


## 二、实验原理

总体网络结构：

![神经网络总体结构](https://dn-anything-about-doc.qbox.me/document-uid291340labid2300timestamp1479458896226.png/wm)

本节课程，我们将实现上图中有监督训练部分。

## 三、实验操作

设置有监督网络结构及参数

```python 
from __future__ import division

# 定义有监督学习参数

supervised_alpha= 0.5 # 有监督学习训练步长
max_epoch = 200 # 有监督学习总训练次数
mini_batch = 14
SJ = []  # 用于保存训练过程的误差值变化
SAcc = [] # 用于记录训练过程中分类器预测的正确率变化过程

# 初始化有监督升级网络结构
SL_layer_srtuc = []
SL_layer_num = 2
SL_layer_struc = [[0, hidden_node],
                  [0, 4]]

# 初始化有监督训练部分神经网络的权值
supervised_weight = []
for l in range(SL_layer_num-1):
    supervised_weight.append(np.random.randn(SL_layer_struc[l+1][1],sum(SL_layer_struc[l])))

#  用于有监督学习的误差调整时的 δ   
delta = []
for l in range(SL_layer_num):
    delta.append([])    

```

导入预先准备好的训练集和测试集数据，及其对应的标记数据。并且对数据进行归一化

```python
# 训练集数据
trainData = DataSet['trainData'] 
trainData = trainData[:,:]   
train_data = np.zeros(trainData.shape)

# 归一化处理
trainData_size = 56  
for i in range(trainData_size):
    tmp = trainData[:,i]
    train_data[:,i] = (tmp - np.mean(tmp)) / np.std(tmp) 
      
train_labels = DataSet['train_labels']
train_labels = train_labels[:,:]

# 测试集数据      
testData = DataSet['testData']
testData = testData[:,:]
test_data = np.zeros(testData.shape)

# 归一化处理
testData_size = 40  
for i in range(testData_size):
    tmp = testData[:,i]
    test_data[:,i] = (tmp - np.mean(tmp)) / np.std(tmp) 
    
test_labels = DataSet['test_labels']
test_labels = test_labels[:,:]
```

利用自编码器获取训练集和测试集降维后的编码：

```python
# 训练集
a = []
a.append(np.zeros((layer_struc[0][1],trainData_size)))
for l in range(hidden_layer-1):
    if l == 0:
        tmpA,tmpZ = feedforward(w[l], a[l], train_data)
        a.append(tmpA)
    else:
        tmpA,tmpZ = feedforward(w[l],a[l], np.zeros((0,trainData_size)))
        a.append(tmpA)

small_trainData = a[hidden_layer-1]

# 测试集
a = []
a.append(np.zeros((layer_struc[0][1],testData_size)))
for l in range(hidden_layer-1):
    if l == 0:
        tmpA,tmpZ = feedforward(w[l], a[l], test_data)
        a.append(tmpA)
    else:
        tmpA,tmpZ = feedforward(w[l],a[l], np.zeros((0,testData_size)))
        a.append(tmpA)
    
small_testData = a[hidden_layer-1]
```

有监督训练过程：

```python
def supervised_training():
    
    global SJ
    global SAcc
    
    print('Supervised training start..')
    for iter in range(max_epoch):
        
        # 随机从数据集中挑取数据进行训练
        ind = list(range(trainData_size))
        random.shuffle(ind)
        
        a = []
        z = []
        z.append([])
        for i in range(int(np.ceil(trainData_size / mini_batch))):
            
            # 网络内部节点
            a.append(small_trainData[:,ind[i*mini_batch:min((i+1)*mini_batch,trainData_size)]])
            # 准备网络训练的外部节点
            x = []
            for l in range(SL_layer_num):
                x.append( np.zeros((0,min((i+1)*mini_batch,trainData_size)-i*mini_batch)))
    
            # 网络的目标输出
            y = train_labels[:,ind[i*mini_batch:min((i+1)*mini_batch,trainData_size)]]
            
            # 进行网络的前向传播计算
            for l in range(SL_layer_num-1):
                a.append([])
                z.append([])
                a[l+1],z[l+1] = feedforward(supervised_weight[l],a[l],x[l])
            
            # 计算网络输出与目标输出的误差值
            delta[SL_layer_num-1] = np.array(a[SL_layer_num-1] - y) * np.array(a[SL_layer_num-1])
            delta[SL_layer_num-1] = delta[SL_layer_num-1] * np.array(1-a[SL_layer_num-1])
            
            # 进行误差反向传播
            for l in range(SL_layer_num-2, 0, -1):
                delta[l] = backprop(supervised_weight[l],z[l],delta[l+1])
    
            for l in range(SL_layer_num-1):
                dw = np.dot(delta[l+1], np.concatenate((a[l],x[l]),axis=0).T) / mini_batch
                supervised_weight[l] = supervised_weight[l] - supervised_alpha * dw
    

            tmpResult = a[SL_layer_num-1]
            SJ.append(np.sum(np.multiply(tmpResult[:] - y[:], tmpResult[:] - y[:]))/2/mini_batch)   
            SAcc.append(float(sum(np.argmax(y, axis=0) == np.argmax(tmpResult, axis=0))/mini_batch))
    
    # 展示训练过程的预测正确率和误差值变化
    print('Supervised learning done!')         
    plt.figure()
    plt.plot(SJ)
    plt.title('loss function')
    plt.figure()
    plt.plot(SAcc)
    plt.title('Accuracy')
```

测试有监督训练的结果，输出其对于训练集和测试集的预测正确率：

```python
def supervised_testing():
    print('Testing..')
    
    # 测试对训练集的预测结果正确率
    tmpA, tmpZ = feedforward(supervised_weight[0], small_trainData, np.zeros((0,trainData_size)))    
    train_pred = np.argmax(tmpA, axis=0)
    train_res = np.argmax(train_labels,axis=0)

    train_acc = float(sum(train_pred == train_res) / trainData_size) * 100
    print('Training accuracy:%.2f%c' % (train_acc,'%'))
    
    # 测试对测试集的预测结果正确率
    tmpA, tmpZ = feedforward(supervised_weight[0], small_testData, np.zeros((0,testData_size)))    
    test_pred = np.argmax(tmpA, axis=0)
    test_res = np.argmax(test_labels, axis=0)
    test_acc = float(sum(test_pred == test_res) / testData_size) * 100
    print('Testing accuracy:%.2f%c' % (test_acc, '%'))
```

设计完所有函数，调用其查看结果
```python
supervised_training()
supervised_testing()

plt.show()
```

## 四、 总结

这次的人脸识别任务课程，我们结合了无监督学习及有监督学习进行了神经网络的训练，可以看到我们的训练效果并不是特别的好。效果不好的原因有很多，网络的参数（学习步长，网络节点数目设置，结构设置）是其一，另外一个就是其实我们的数据量很小，仅有80张无标记数据进行特征提取，且有监督阶段也仅用了14张有标记图片。而在现在的神经网络应用中，其实是有大量的无标记数据的，及有专门聘请人进行筛选标记数据的数据库，如[imageNet](http://image-net.org/)，很多`计算机视觉`的任务也会应用这个数据库的数据进行算法的性能测试。有兴趣的同学可以基于我们这个课程，自己下载数据对这次课程的神经网络结构进行拓展。

本次课程的所有源码可通过以下命令获得：

```bash
wget http://labfile.oss.aliyuncs.com/courses/707/face_recognition.py
```