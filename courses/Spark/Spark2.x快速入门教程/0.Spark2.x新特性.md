# Spark2.x 课程介绍

## 一、实验介绍

### 1.1 实验内容

Spark 是 Apache 高级项目里面较火的大数据处理的计算引擎，对比 Spark 1.x 版本，Spark 2.x 有哪些改进，本节课主要讲解 Spark2.x 新特性。

### 1.2 先学课程

- Scala [https://www.shiyanlou.com/courses/?course_type=all&tag=Scala&fee=all](https://www.shiyanlou.com/courses/?course_type=all&tag=Scala&fee=all)

为了保证可以在实验楼环境中完成本次实验，我们在原书内容基础上补充了一系列的实验指导，比如实验截图，代码注释，帮助您更好得实战。如果您对于实验有疑惑或者建议可以随时在讨论区中提问，与同学们一起探讨。

### 1.3 实验知识点

- 对标准的 SQL 支持
- DataFrame 和 Dataset API 介绍
- Structured Streaming

### 1.4 实验环境

- hadoop-2.6.1
- spark-2.1.0-bin-hadoop2.6
- scala-2.11.7
- Xfce 终端

本课程属于中等难度级别，适合具有 scala 基础的用户，如果对 spark1.x 了解能够更好的上手本课程。

## 二、Spark2.x 介绍

### 2.1 Spark2.x 与 Spark1.x 关系

Spark2.x 引入了很多优秀特性，性能上有较大提升，API 更易用。在 “编程统一” 方面非常惊艳，实现了离线计算和流计算 API 的统一，实现了 Spark sql 和 Hive Sql 操作 API 的统一。Spark 2.x 基本上是基于 Spark 1.x 进行了更多的功能和模块的扩展，及性能的提升。

### 2.2 Spark2.x 新特性

#### 1). whole－stage code generation

大幅提高计算性能，因为把物理计划变成硬编码，每秒处理的 sql 中的数据量增加十倍，即对物理执行的多次调用转化为代码 for 循环，减少执行的函数调用次数，当数据记录多时，这个调用次数时很大的。

#### 2). sparksession 实现 hivecontext 和 sqlcontext 统一

Spark2.0 中引入了 SparkSession 的概念，它为用户提供了一个统一的切入点来使用 Spark 的各项功能，用户不但可以使用 DataFrame 和 Dataset 的各种 API，学习 Spark2 的难度也会大大降低。

#### 3). 统一 Scala 和 Java 中 DataFrames 和 Datasets 的 API。

它们都是提供给用户使用，包括各类操作接口的 API，1.3 版本引入 DataFrame，1.6 版本引入 Dataset，Spark2.0 提供的功能是将二者统一，DataFrame 仅仅是 Dataset 的一个别名。有类型的方法 (typed methods)（比如：map, filter, groupByKey）和无类型的方法(untyped methods)(比如：select, groupBy) 目前在 Dataset 类上可用。同样，新的 Dataset 接口也在 Structured Streaming 中使用。因为编译时类型安全 (compile-time type-safety) 在 Python 和 R 中并不是语言特性，所以 Dataset 的概念并不在这些语言中提供相应的 API。而 DataFrame 仍然作为这些语言的主要编程抽象。

#### 4). Structured Streaming

Spark Streaming 是把流式计算看成一个一个的离线计算来完成流式计算，提供了一套 Dstream 的流 API，相比于其他的流式计算，Spark Streaming 的优点是容错性和吞吐量上要有优势，在 2.0 以前的版本，用户在使用时，如果有流计算，又有离线计算，就需要用二套 API 去编写程序，一套是 RDD API，一套是 Dstream API。而且 Dstream API 在易用性上远不如 SQL 或 DataFrame。

为了真正将流式计算和离线计算在编程 API 上统一，同时也让 Streaming 作业能够享受 DataFrame/Dataset 上所带来的优势：性能提升和 API 易用，于是提出了 Structured Streaming。最后我们只需要基于 DataFrame/Dataset 可以开发离线计算和流式计算的程序。

#### 5). 其它特性

mllib 里的计算用 DataFrame-based API 代替以前的 RDD 计算逻辑，提供更多的 R 语言算法，默认使用 Scala 2.11 编译与运行。

## 三、总结

本节主要讲解了 Spark 2.x 新特性，从大体上了解 Spark2.x ，为接下来的学习做准备。

本实验参考下列链接制作：

- [Spark 2.0 技术预览：更容易、更快速、更智能](http://mp.weixin.qq.com/s?__biz=MzA5MTc0NTMwNQ==&mid=2650713539&idx=1&sn=ac7e596fa048db57c24c5ae514459dea&scene=1&srcid=0513RrB8NG3iMm5aZajjXyHN#wechat_redirect)
- [Spark 2.0 技术新特性总结](http://www.aboutyun.com/thread-19170-1-1.html)